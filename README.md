# Smart Chat Assistant



A Streamlit-based chat interface powered by Google’s Gemini models, featuring multi-session chat history, search, export (text/JSON), and basic session management tools.



## Features



*   Streamlit UI with wide-layout chat interface and persistent multi-session history in session_state.

*   Automatic model fallback across Gemini models: gemini-2.0-flash-exp → gemini-1.5-flash → gemini-1.5-pro.

*   New Chat creation, session switching, search across titles and messages, and auto-title from first user message.

*   Export current chat to .txt and all chats to .json directly from the sidebar.

*   One-click clear current chat and archive old chats (older than 7 days) with counts.

*   Inline error handling and loading spinners during model calls.



## Important Note on API Keys



Do not hardcode API keys in source files. Move the API key out of code into environment variables or a secrets manager (e.g., Streamlit secrets, .env) before committing. The current file contains a placeholder constant and should be replaced with a secure configuration.



## Tech Stack



*   Python

*   Streamlit for the UI and state.

*   google-generativeai for Gemini model access.



## Getting Started



1.  *Clone and install*

    *   Create and activate a virtual environment.

    *   Install dependencies:

        *   streamlit

        *   google-generativeai



2.  *Configure API key*

    *   Preferred: set an environment variable:

        *   On macOS/Linux:


!pip install streamlit google-generativeai
!streamlit run app.py


## First run checks

The app will try models in order: gemini-2.0-flash-exp, gemini-1.5-flash, gemini-1.5-pro.

If initialization fails, an API error banner appears.

## Usage

Start a new chat from the sidebar; the first user message becomes the session title (trimmed).

Type a message in the chat input; assistant replies are generated by the selected Gemini model.

Search chats by keywords; matches consider both titles and messages.
